<!DOCTYPE html><html lang="en"><head><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-160213843-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-160213843-1');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, shrink-to-fit=no"><meta name="keywords" content="Computational Photography,Deep Sensing,Deep Optics,Task-Oriented Sensing,Video Compressive Sensing,Coded Exposure Camera,Coded Aperture Camera,Light Field Camera,Focus Sweep Camera,Time of Flight,Depth From Defocus,Multi-tap CMOS Image Sensor,コンピュテーショナルフォトグラフィ,符号化露光カメラ,符号化露光画像,符号化開口カメラ,ライトフィールドカメラ,圧縮ビデオセンシング,マルチタップCMOSイメージセンサ,フォーカススイープカメラ"><title>Hajime Nagahara - Nagahara Lab.</title><meta name="description" content="長原研究室ではコンピュテーショナルフォトグラフィ (Computational Photography) をテーマに研究している． 従来のカメラは人間が見て意味のあるものを撮像するが，コンピュータビジョンの様々なタスクで使用する際にはカメラは必ずしも人間が見て意味のあるものを撮像する必要はない． コンピュテーショナルフォトグラフィでは，従来の撮像過程を改変し後のタスクに適したセンシングを考えることで従来なし得なかった撮像・画像処理を可能にする． 我々の研究室ではこれまでに符号化露光カメラや符号化開口カメラ，フォーカススイープカメラなどの様々なタスクに応用可能なカメラを開発・研究してきた．"><link rel="shortcut icon" type="image/png" href="/favicon.ico"><link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" type="text/css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" type="text/css" rel="stylesheet"><link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" type="text/css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" type="text/css" rel="stylesheet"><link href="/assets/main.css" type="text/css" rel="stylesheet"><link href="/feed.xml" type="application/rss+xml" title="Nagahara Lab." rel="alternate"><link href="https://nagahara-lab.github.io/members/nagahara" rel="canonical"></head><body><nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav"><div class="container"><a class="navbar-brand" href="/">Nagahara Lab.</a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><Menu></Menu><i class="fa fa-bars"></i></button><div class="collapse navbar-collapse" id="navbarResponsive"><ul class="navbar-nav ml-auto"><li class="nav-item"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/projects">Projects</a></li><li class="nav-item"><a class="nav-link" href="/members">Members</a></li><li class="nav-item"><a class="nav-link" href="/publications">Publications</a></li><li class="nav-item"><a class="nav-link" href="/news">News</a></li><li class="nav-item"><a class="nav-link" href="/contact">Contact</a></li><li class="nav-item trans"><a class="nav-link" href="/ja/members/nagahara">日本語</a></li></ul></div></div></nav><header class="masthead" style="background-image: url('/assets/imgs/TOP.webp')"><div class="overlay"></div><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><div class="page-heading"><h1>Hajime Nagahara</h1></div></div></div></div></header>
<div class="container"><div class="row"><div class="col-lg-3"><img src="/assets/imgs/members/nagahara.jpeg" width="100%"/></div><div class="col-lg-9 mx-auto"><h1>Hajime Nagahara</h1><br/><div class="row"><div class="col-lg-4 offset-lg-1"><b>Job Title:</b></div><div class="col-lg-7 mx-auto">Professor</div></div>
<div class="row"><div class="col-lg-4 offset-lg-1"><b>Academic Degree:</b></div><div class="col-lg-7 mx-auto">Ph.D (Eng.)</div></div>
<div class="row"><div class="col-lg-4 offset-lg-1"><b>Organization Name:</b></div><div class="col-lg-7 mx-auto"><a href="http://www.ids.osaka-u.ac.jp">Osaka University Institute for Datability Science</a></div></div>
<div class="row"><div class="col-lg-4 offset-lg-1"><b>Research topics:</b></div><div class="col-lg-7 mx-auto">Computational Photography, Computer Vision, Image Processing</div></div></div></div><br/><div class="row"><div class="col-lg-10 col-md-10 mx-auto"><h4>Employment Record</h4><ul class="history"><li>2017.04 - , Professor, Osaka University Institute for Datability Science</li><li>2010.04 - 2017.03, Associate Professor, Faculty of Information Science and Electrical Engineering, Kyushu University</li><li>2007.04 - 2010.03, Assistant Professor, Graduate School of Engineering Science, Osaka University</li><li>2007.10 - 2008.09, Visiting Researcher, Colombia University, USA</li><li>2003.07 - 2007.03, Research Assistant, Graduate School of Engineering Science, Osaka University</li><li>2005.09, Visiting Associate Professor, University of Picardie Jules Verns, France</li><li>2001.07 - 2003.06, Research Associate, Japan Society for the Promotion of Science</li></ul><br/><h4>Education</h4><ul class="history"><li>2001.06, Ph. D in Engineering, Osaka University Graduate School, Division of Engineering Science</li><li>1998.03, Master of Enginnering, Yamaguchi University Graduate School, Division of Science and Engineering</li><li>1996.03, Bachelor of Enginnering, Yamaguchi University Faculty of Engineering</li></ul><br/><h4>Award</h4><ul class="history"><li>Honorable Mention Award of 10th ACM symposium on virtual reality software and technology, Hajime Nagahara, Yasushi Yagi, Masahiko Yachida, ACM, 2003.10</li><li>Finalist for T. J. Tarn Best Paper in Robotics, Trung Ngo Thanh, Yusuke Sakaguchi, Hajime Nagahara, Masahiko Yachida, IEEE, 2006.12</li></ul><br/></div></div><br/><div class="row"><div class="col-lg-10 col-md-10 mx-auto"><h2>Publications</h2><h4>Journals (Peer-reviewed)</h4><ol reversed="reversed"><li class="publications"><span>Michitaka Yoshida, Toshiki Sonoda, Hajime Nagahara, Kenta Endo, Yukinobu Sugiyama, Rin-Ichiro Taniguchi</span><br/><span>High-Speed Imaging Using CMOS Image Sensor With Quasi Pixel-Wise Exposure</span><br/><span>
IEEE Transactions on Computational Imaging,



Vol.6,



pp.463-476,


2020.01
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>, <a href="https://doi.org/10.1109/TCI.2019.2956885">DOI</a>
<pre><code class="language-bibtex">@ARTICLE{8918110,
  author={M. {Yoshida} and T. {Sonoda} and H. {Nagahara} and K. {Endo} and Y. {Sugiyama} and R. {Taniguchi}},
  journal={IEEE Transactions on Computational Imaging},
  title={High-Speed Imaging Using CMOS Image Sensor With Quasi Pixel-Wise Exposure},
  year={2020},
  volume={6},
  number={},
  pages={463-476},
  keywords={Image reconstruction;CMOS image sensors;Spatial resolution;Compressed sensing;Prototypes;Compressive sensing;video reconstruction},
  doi={10.1109/TCI.2019.2956885},
  ISSN={2573-0436},
  month={},
}</code></pre></span></li></ol><h4>International Conferences (Peer-reviewed)</h4><ol reversed="reversed"><li class="publications"><span>Michitaka Yoshida, Akihiko Torii, Masatoshi Okutomi, Kenta Endo, Yukinobu Sugiyama, Rin-Ichiro Taniguchi, Hajime Nagahara</span><br/><span>Joint optimization for compressive video sensing and reconstruction under hardware constraints</span><br/><span>

Proceedings of the European Conference on Computer Vision (ECCV),




pp.634-649,


2018.09
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>
<pre><code class="language-bibtex">@inproceedings{yoshida2018joint,
  author={Yoshida, Michitaka and Torii, Akihiko and Okutomi, Masatoshi and Endo, Kenta and Sugiyama, Yukinobu and Taniguchi, Rin-ichiro and Nagahara, Hajime},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  title={Joint optimization for compressive video sensing and reconstruction under hardware constraints},
  year={2018},
  pages={634--649},
}</code></pre></span></li></ol><h4>Domestic Conferences (Non-Peer-reviewed)</h4><ol reversed="reversed"><li class="publications"><span>吉田 道隆, 鳥居 秋彦, 奥富 正敏, 遠藤 健太, 杉山 行信, 谷口 倫一郎, 長原 一</span><br/><span>ハードウェアの制約を考慮した圧縮ビデオセンシングにおける圧縮と再構成の同時最適化</span><br/><span>

第21回画像の認識・理解シンポジウム(MIRU2018),





MIRU2018
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>
<pre><code class="language-bibtex">@inproceedings{MIRU2018Yoshida,
  author={吉田 道隆, 鳥居 秋彦, 奥富 正敏, 遠藤 健太, 杉山 行信, 谷口 倫一郎, 長原 一},
  booktitle={第21回画像の認識・理解シンポジウム(MIRU2018)},
  title={ハードウェアの制約を考慮した圧縮ビデオセンシングにおける圧縮と再構成の同時最適化},
  year={2018},
}</code></pre></span></li></ol></div></div></div><hr><footer><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><ul class="list-inline text-center"><li class="list-inline-item"><a href="mailto:contact@ids.osaka-u.ac.jp"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="far fa-envelope fa-stack-1x fa-inverse"></i></span></a></li>



<li class="list-inline-item"><a href="https://github.com/nagahara-lab"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><br><p style="font-size: 1.5rem;">Osaka University Institute for Datability Science</p><p style="font-size: 1rem;">TechnoAlliance Building C503, 2-8 Yamadaoka, Suita, Osaka 565-0871 Japan</p><p class="copyright text-muted">Copyright &copy; Nagahara Lab. 2020</p></div></div></div></footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/startbootstrap-clean-blog/5.0.8/css/clean-blog.min.css"></script>

<script src="/assets/scripts.js"></script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script>
$(function (){
  $(".language-bibtex").each(function(){
    var $this = $(this);
    $this.hide();
    $this.parents("span").children("a.bibtex").click(function(){
      if($(this).data("status")) {
        $(this).data("status", false);
        $this.hide();
      } else {
        $(this).data("status", true);
        $this.show();
      }
    });
  });
});
</script>



</body></html>
<!DOCTYPE html><html lang="en"><head><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-160213843-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-160213843-1');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, shrink-to-fit=no"><meta name="keywords" content="Computational Photography,Deep Sensing,Deep Optics,Task-Oriented Sensing,Video Compressive Sensing,Coded Exposure Camera,Coded Aperture Camera,Light Field Camera,Focus Sweep Camera,Time of Flight,Depth From Defocus,Multi-tap CMOS Image Sensor,コンピュテーショナルフォトグラフィ,符号化露光カメラ,符号化露光画像,符号化開口カメラ,ライトフィールドカメラ,圧縮ビデオセンシング,マルチタップCMOSイメージセンサ,フォーカススイープカメラ"><title>Nagahara Lab. - Nagahara Lab.</title><meta name="description" content="長原研究室ではコンピュテーショナルフォトグラフィ (Computational Photography) をテーマに研究している． 従来のカメラは人間が見て意味のあるものを撮像するが，コンピュータビジョンの様々なタスクで使用する際にはカメラは必ずしも人間が見て意味のあるものを撮像する必要はない． コンピュテーショナルフォトグラフィでは，従来の撮像過程を改変し後のタスクに適したセンシングを考えることで従来なし得なかった撮像・画像処理を可能にする． 我々の研究室ではこれまでに符号化露光カメラや符号化開口カメラ，フォーカススイープカメラなどの様々なタスクに応用可能なカメラを開発・研究してきた．"><link rel="shortcut icon" type="image/png" href="/favicon.ico"><link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" type="text/css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" type="text/css" rel="stylesheet"><link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" type="text/css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" type="text/css" rel="stylesheet"><link href="/assets/main.css" type="text/css" rel="stylesheet"><link href="/feed.xml" type="application/rss+xml" title="Nagahara Lab." rel="alternate"><link href="https://nagahara-lab.github.io/2/" rel="canonical"></head><body><nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav"><div class="container"><a class="navbar-brand" href="/">Nagahara Lab.</a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><Menu></Menu><i class="fa fa-bars"></i></button><div class="collapse navbar-collapse" id="navbarResponsive"><ul class="navbar-nav ml-auto"><li class="nav-item"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/projects">Projects</a></li><li class="nav-item"><a class="nav-link" href="/members">Members</a></li><li class="nav-item"><a class="nav-link" href="/publications">Publications</a></li><li class="nav-item"><a class="nav-link" href="/news">News</a></li><li class="nav-item"><a class="nav-link" href="/contact">Contact</a></li></ul></div></div></nav><header class="masthead" style="background-image: url('/assets/imgs/TOP.webp')"><div class="overlay"></div><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><div class="page-heading"><h2>Osaka University</h2><h1>Nagahara Lab.</h1><span class="subheading">We focus on Computational Photography and Computer Vision.</span></div></div></div></div></header>
<div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><h1>Welcome to Nagahara lab.</h1>
<p>
  Welcome to Nagahara lab., Osaka University Institute for Datability Science.
  We focus on Computational Photography and Computer Vision.
</p>

<h2 class="section-heading">What's New</h2><article class="post-preview"><a href="/2020/01/23/cvim220.html"><h5>情報処理学会コンピュータビジョンとイメージメディア (CVIM) 研究会 (第220回)</h5><h6>M2の大河原君が口頭発表とポスター発表を行いました．</h6></a><p class="post-meta"><Posted>by</Posted>
Nagahara Lab.
<on></on>January 23, 2020</p></article><hr/><article class="post-preview"><a href="/2019/11/28/tci2019.html"><h5>IEEE Transactions on Computational Imaging (Volume: 6)</h5><h6>D1の吉田君の論文がIEEE Transactions on Computational Imaging (Volume: 6) に採択されました．</h6></a><p class="post-meta"><Posted>by</Posted>
Nagahara Lab.
<on></on>November 28, 2019</p></article><hr/><article class="post-preview"><a href="/2019/09/02/fit2019.html"><h5>第18回情報科学技術フォーラム (FIT 2019)</h5><h6>D1の吉田君が招待講演を行いました．</h6></a><p class="post-meta"><Posted>by</Posted>
Nagahara Lab.
<on></on>September 02, 2019</p></article><hr/><article class="post-preview"><a href="/2019/07/31/miru2019.html"><h5>第22回 画像の認識・理解シンポジウム (MIRU 2019)</h5><h6>D1の吉田君とM2の大河原君が発表を行いました．</h6></a><p class="post-meta"><Posted>by</Posted>
Nagahara Lab.
<on></on>July 31, 2019</p></article><hr/><article class="post-preview"><a href="/2019/05/16/iccp2019.html"><h5>International Conference on Computational Photography (ICCP2019)</h5><h6>D1の吉田君がデモンストレーション発表を行いました．</h6></a><p class="post-meta"><Posted>by</Posted>
Nagahara Lab.
<on></on>May 16, 2019</p></article><hr/><div class="clearfix"><a class="btn btn-primary float-right" href="/news">View All News &rarr;</a></div></div></div></div><hr><footer><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><ul class="list-inline text-center"><li class="list-inline-item"><a href="mailto:contact@ids.osaka-u.ac.jp"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="far fa-envelope fa-stack-1x fa-inverse"></i></span></a></li>



<li class="list-inline-item"><a href="https://github.com/nagahara-lab"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><br><p style="font-size: 1.5rem;">Osaka University Institute for Datability Science</p><p style="font-size: 1rem;">TechnoAlliance Building C503, 2-8 Yamadaoka, Suita, Osaka 565-0871 Japan</p><p class="copyright text-muted">Copyright &copy; Nagahara Lab. 2020</p></div></div></div></footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/startbootstrap-clean-blog/5.0.8/css/clean-blog.min.css"></script>

<script src="/assets/scripts.js"></script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script>
$(function (){
  $(".language-bibtex").each(function(){
    var $this = $(this);
    var title = $this.text().match(/[^kK]title\s?=\s?{(.*?)},?/)[1] || "BibTeX";
    $this.hide();
    $this.parent().before($("<a>", {text: title, "data-status": "false", "class": "bibtex"}).click(function(){
      if($(this).data("status")) {
        $(this).data("status", false);
        $this.hide();
      } else {
        $(this).data("status", true);
        $this.show();
      }
    }));
  });
});
</script>



</body></html>
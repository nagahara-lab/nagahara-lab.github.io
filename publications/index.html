<!DOCTYPE html><html lang="en"><head><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-160213843-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-160213843-1');
</script>

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, shrink-to-fit=no"><meta name="keywords" content="Computational Photography,Deep Sensing,Deep Optics,Task-Oriented Sensing,Video Compressive Sensing,Coded Exposure Camera,Coded Aperture Camera,Light Field Camera,Focus Sweep Camera,Time of Flight,Depth From Defocus,Multi-tap CMOS Image Sensor,コンピュテーショナルフォトグラフィ,符号化露光カメラ,符号化露光画像,符号化開口カメラ,ライトフィールドカメラ,圧縮ビデオセンシング,マルチタップCMOSイメージセンサ,フォーカススイープカメラ"><title>Publications - Nagahara Lab.</title><meta name="description" content="長原研究室ではコンピュテーショナルフォトグラフィ (Computational Photography) をテーマに研究している． 従来のカメラは人間が見て意味のあるものを撮像するが，コンピュータビジョンの様々なタスクで使用する際にはカメラは必ずしも人間が見て意味のあるものを撮像する必要はない． コンピュテーショナルフォトグラフィでは，従来の撮像過程を改変し後のタスクに適したセンシングを考えることで従来なし得なかった撮像・画像処理を可能にする． 我々の研究室ではこれまでに符号化露光カメラや符号化開口カメラ，フォーカススイープカメラなどの様々なタスクに応用可能なカメラを開発・研究してきた．"><link rel="shortcut icon" type="image/png" href="/favicon.ico"><link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" type="text/css" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" type="text/css" rel="stylesheet"><link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" type="text/css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" type="text/css" rel="stylesheet"><link href="/assets/main.css" type="text/css" rel="stylesheet"><link href="/feed.xml" type="application/rss+xml" title="Nagahara Lab." rel="alternate"><link href="https://nagahara-lab.github.io/publications/" rel="canonical"></head><body><nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav"><div class="container"><a class="navbar-brand" href="/">Nagahara Lab.</a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><Menu></Menu><i class="fa fa-bars"></i></button><div class="collapse navbar-collapse" id="navbarResponsive"><ul class="navbar-nav ml-auto"><li class="nav-item"><a class="nav-link" href="/">Home</a></li><li class="nav-item"><a class="nav-link" href="/projects">Projects</a></li><li class="nav-item"><a class="nav-link" href="/members">Members</a></li><li class="nav-item"><a class="nav-link" href="/publications">Publications</a></li><li class="nav-item"><a class="nav-link" href="/news">News</a></li><li class="nav-item"><a class="nav-link" href="/contact">Contact</a></li></ul></div></div></nav><header class="masthead" style="background-image: url('/assets/imgs/TOP.webp')"><div class="overlay"></div><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><div class="page-heading"><h1>Publications</h1></div></div></div></div></header><div class="container"><div class="row"><div class="col-lg-12 col-md-12 mx-auto"><h3>Journals (Peer-reviewed)</h3><ol reversed="reversed"><li class="publications"><span>Michitaka Yoshida, Toshiki Sonoda, Hajime Nagahara, Kenta Endo, Yukinobu Sugiyama, Rin-Ichiro Taniguchi</span><br/><span>High-Speed Imaging Using CMOS Image Sensor With Quasi Pixel-Wise Exposure</span><br/><span>
IEEE Transactions on Computational Imaging,



Vol.6,



pp.463-476,


2020.01
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>, <a href="https://doi.org/10.1109/TCI.2019.2956885">DOI</a>
<pre><code class="language-bibtex">@ARTICLE{8918110,
  author={M. {Yoshida} and T. {Sonoda} and H. {Nagahara} and K. {Endo} and Y. {Sugiyama} and R. {Taniguchi}},
  journal={IEEE Transactions on Computational Imaging},
  title={High-Speed Imaging Using CMOS Image Sensor With Quasi Pixel-Wise Exposure},
  year={2020},
  volume={6},
  number={},
  pages={463-476},
  keywords={Image reconstruction;CMOS image sensors;Spatial resolution;Compressed sensing;Prototypes;Compressive sensing;video reconstruction},
  doi={10.1109/TCI.2019.2956885},
  ISSN={2573-0436},
  month={},
}</code></pre></span></li></ol><h3>International Conferences (Peer-reviewed)</h3><ol reversed="reversed"><li class="publications"><span>Michitaka Yoshida, Akihiko Torii, Masatoshi Okutomi, Kenta Endo, Yukinobu Sugiyama, Rin-Ichiro Taniguchi, Hajime Nagahara</span><br/><span>Joint optimization for compressive video sensing and reconstruction under hardware constraints</span><br/><span>

Proceedings of the European Conference on Computer Vision (ECCV),




pp.634-649,


2018.09
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>
<pre><code class="language-bibtex">@inproceedings{yoshida2018joint,
  author={Yoshida, Michitaka and Torii, Akihiko and Okutomi, Masatoshi and Endo, Kenta and Sugiyama, Yukinobu and Taniguchi, Rin-ichiro and Nagahara, Hajime},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  title={Joint optimization for compressive video sensing and reconstruction under hardware constraints},
  year={2018},
  pages={634--649},
}</code></pre></span></li></ol><h3>Domestic Conferences (Non-Peer-reviewed)</h3><ol reversed="reversed"><li class="publications"><span>吉田 道隆, 鳥居 秋彦, 奥富 正敏, 遠藤 健太, 杉山 行信, 谷口 倫一郎, 長原 一</span><br/><span>ハードウェアの制約を考慮した圧縮ビデオセンシングにおける圧縮と再構成の同時最適化</span><br/><span>

第21回画像の認識・理解シンポジウム(MIRU2018),





MIRU2018
</span><br/><span><a class="bibtex" data-status="false">BibTeX</a>
<pre><code class="language-bibtex">@inproceedings{MIRU2018Yoshida,
  author={吉田 道隆, 鳥居 秋彦, 奥富 正敏, 遠藤 健太, 杉山 行信, 谷口 倫一郎, 長原 一},
  booktitle={第21回画像の認識・理解シンポジウム(MIRU2018)},
  title={ハードウェアの制約を考慮した圧縮ビデオセンシングにおける圧縮と再構成の同時最適化},
  year={2018},
}</code></pre></span></li></ol></div></div></div><hr><footer><div class="container"><div class="row"><div class="col-lg-8 col-md-10 mx-auto"><ul class="list-inline text-center"><li class="list-inline-item"><a href="mailto:contact@ids.osaka-u.ac.jp"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="far fa-envelope fa-stack-1x fa-inverse"></i></span></a></li>



<li class="list-inline-item"><a href="https://github.com/nagahara-lab"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i><i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li></ul><br><p style="font-size: 1.5rem;">Osaka University Institute for Datability Science</p><p style="font-size: 1rem;">TechnoAlliance Building C503, 2-8 Yamadaoka, Suita, Osaka 565-0871 Japan</p><p class="copyright text-muted">Copyright &copy; Nagahara Lab. 2020</p></div></div></div></footer><script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/startbootstrap-clean-blog/5.0.8/css/clean-blog.min.css"></script>

<script src="/assets/scripts.js"></script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script>
$(function (){
  $(".language-bibtex").each(function(){
    var $this = $(this);
    $this.hide();
    $this.parents("span").children("a.bibtex").click(function(){
      if($(this).data("status")) {
        $(this).data("status", false);
        $this.hide();
      } else {
        $(this).data("status", true);
        $this.show();
      }
    });
  });
});
</script>



</body></html>